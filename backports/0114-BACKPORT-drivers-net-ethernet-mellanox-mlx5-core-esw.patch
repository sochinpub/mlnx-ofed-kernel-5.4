From: Valentine Fatiev <valentinef@mellanox.com>
Subject: [PATCH] BACKPORT:
 drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c

Change-Id: I849b9d560a18959199299aca842d60b1d6635000
---
 .../ethernet/mellanox/mlx5/core/eswitch_offloads.c | 102 +++++++++++++++++----
 1 file changed, 83 insertions(+), 19 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch_offloads.c
@@ -2645,6 +2645,7 @@ int esw_offloads_load_rep(struct mlx5_es
 
 	rep = mlx5_eswitch_get_rep(esw, vport_num);
 
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK) {
 		if (atomic_read(&rep->rep_data[REP_ETH].state) == REP_REGISTERED) {
 			err = mlx5_esw_offloads_devlink_port_register(esw, vport_num);
@@ -2652,6 +2653,7 @@ int esw_offloads_load_rep(struct mlx5_es
 				return err;
 		}
 	}
+#endif
 
 	err = mlx5_esw_offloads_rep_load(esw, vport_num);
 	if (err)
@@ -2659,8 +2661,10 @@ int esw_offloads_load_rep(struct mlx5_es
 	return err;
 
 load_err:
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK)
 		mlx5_esw_offloads_devlink_port_unregister(esw, vport_num);
+#endif
 	return err;
 }
 
@@ -2671,8 +2675,10 @@ void esw_offloads_unload_rep(struct mlx5
 
 	mlx5_esw_offloads_rep_unload(esw, vport_num);
 
+#ifdef HAVE_DEVLINK_PORT_ATRRS_SET_GET_SUPPORT
 	if (vport_num != MLX5_VPORT_UPLINK)
 		mlx5_esw_offloads_devlink_port_unregister(esw, vport_num);
+#endif
 }
 
 static int esw_set_uplink_slave_ingress_root(struct mlx5_core_dev *master,
@@ -3153,7 +3159,11 @@ u32 mlx5_esw_match_metadata_alloc(struct
 
 	/* Metadata is 4 bits of PFNUM and 12 bits of unique id */
 	/* Use only non-zero vport_id (2-4095) for all PF's */
+#ifdef HAVE_IDA_ALLOC_RANGE
 	id = ida_alloc_range(&esw->offloads.vport_metadata_ida,
+#else
+	id = ida_simple_get(&esw->offloads.vport_metadata_ida,
+#endif
 			     MLX5_ESW_METADATA_RSVD_UPLINK + 1,
 			     vport_end_ida, GFP_KERNEL);
 	if (id < 0)
@@ -3167,7 +3177,11 @@ void mlx5_esw_match_metadata_free(struct
 	u32 vport_bit_mask = (1 << ESW_VPORT_BITS) - 1;
 
 	/* Metadata contains only 12 bits of actual ida id */
-	ida_free(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#ifdef HAVE_IDA_FREE
+       ida_free(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#else
+	ida_simple_remove(&esw->offloads.vport_metadata_ida, metadata & vport_bit_mask);
+#endif
 }
 
 static int esw_offloads_vport_metadata_setup(struct mlx5_eswitch *esw,
@@ -3649,7 +3663,7 @@ static void esw_destroy_default_offloads
 
 static int load_reps_all_vport(struct mlx5_eswitch *esw, u8 rep_type) 
 {
-	struct mlx5_eswitch_rep *rep;
+	struct mlx5_eswitch_rep *rep = NULL;
 	struct mlx5_vport *vport;
 	int ret;
 	unsigned long i;
@@ -4110,14 +4124,23 @@ static int eswitch_devlink_esw_mode_chec
 		!mlx5_core_is_ecpf_esw_manager(esw->dev)) ? -EOPNOTSUPP : 0;
 }
 
-int mlx5_devlink_eswitch_mode_set(struct devlink *devlink, u16 mode,
-				  struct netlink_ext_ack *extack)
+int mlx5_devlink_eswitch_mode_set(struct devlink *devlink, u16 mode
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+				 , struct netlink_ext_ack *extack
+#endif
+				 )
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	u16 cur_mlx5_mode, mlx5_mode = 0;
 	struct mlx5_eswitch *esw;
 	struct mlx5_lag *ldev;
 	
 	int err = 0;
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#endif
 
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
@@ -4149,12 +4172,14 @@ int mlx5_devlink_eswitch_mode_set(struct
 	ldev = mlx5_lag_disable(esw->dev);
 
 	if (mode == DEVLINK_ESWITCH_MODE_SWITCHDEV) {
+#ifdef HAVE_DEVLINK_TRAP_SUPPORT
 		if (mlx5_devlink_trap_get_num_active(esw->dev)) {
 			NL_SET_ERR_MSG_MOD(extack,
 					   "Can't change mode while devlink traps are active");
 			err = -EOPNOTSUPP;
 			goto unlock;
 		}
+#endif
 		err = esw_offloads_start(esw, extack, ldev);
 	} else if (mode == DEVLINK_ESWITCH_MODE_LEGACY) {
 		err = esw_offloads_stop(esw, extack, ldev);
@@ -4181,14 +4206,12 @@ int mlx5_devlink_eswitch_mode_get(struct
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
 
-	mutex_lock(&esw->mode_lock);
 	err = eswitch_devlink_esw_mode_check(esw);
 	if (err)
 		goto unlock;
 
 	err = esw_mode_to_devlink(esw->mode, mode);
 unlock:
-	mutex_unlock(&esw->mode_lock);
 	return err;
 }
 
@@ -4223,14 +4246,23 @@ revert_inline_mode:
 	return err;
 }
 
-int mlx5_devlink_eswitch_inline_mode_set(struct devlink *devlink, u8 mode,
-					 struct netlink_ext_ack *extack)
+int mlx5_devlink_eswitch_inline_mode_set(struct devlink *devlink, u8 mode
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+				 	, struct netlink_ext_ack *extack
+#endif
+				 	)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw;
 	u8 mlx5_mode;
 	int err;
 
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#endif
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
@@ -4245,6 +4277,7 @@ int mlx5_devlink_eswitch_inline_mode_set
 		if (mode == DEVLINK_ESWITCH_INLINE_MODE_NONE)
 			goto out;
 		fallthrough;
+
 	case MLX5_CAP_INLINE_MODE_L2:
 		NL_SET_ERR_MSG_MOD(extack, "Inline mode can't be set");
 		err = -EOPNOTSUPP;
@@ -4288,24 +4321,35 @@ int mlx5_devlink_eswitch_inline_mode_get
 	if (IS_ERR(esw))
 		return PTR_ERR(esw);
 
-	mutex_lock(&esw->mode_lock);
 	err = eswitch_devlink_esw_mode_check(esw);
 	if (err)
 		goto unlock;
 
 	err = esw_inline_mode_to_devlink(esw->offloads.inline_mode, mode);
 unlock:
-	mutex_unlock(&esw->mode_lock);
 	return err;
 }
 
 int mlx5_devlink_eswitch_encap_mode_set(struct devlink *devlink,
-					enum devlink_eswitch_encap_mode encap,
-					struct netlink_ext_ack *extack)
+#ifdef HAVE_DEVLINK_HAS_ESWITCH_ENCAP_MODE_SET_GET_WITH_ENUM
+					enum devlink_eswitch_encap_mode encap
+#else
+					u8 encap
+#endif
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+				 	, struct netlink_ext_ack *extack
+#endif
+				 	)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw;
 	int err;
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#endif
 
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
@@ -4363,7 +4407,11 @@ unlock:
 }
 
 int mlx5_devlink_eswitch_encap_mode_get(struct devlink *devlink,
+#ifdef HAVE_DEVLINK_HAS_ESWITCH_ENCAP_MODE_SET_GET_WITH_ENUM
 					enum devlink_eswitch_encap_mode *encap)
+#else
+					u8 *encap)
+#endif
 {
 	struct mlx5_eswitch *esw;
 	int err;
@@ -4373,14 +4421,12 @@ int mlx5_devlink_eswitch_encap_mode_get(
 		return PTR_ERR(esw);
 
 
-	mutex_lock(&esw->mode_lock);
 	err = eswitch_devlink_esw_mode_check(esw);
 	if (err)
 		goto unlock;
 
 	*encap = esw->offloads.encap;
 unlock:
-	mutex_unlock(&esw->mode_lock);
 	return 0;
 }
 
@@ -4401,14 +4447,24 @@ mlx5_eswitch_vport_has_rep(const struct
 }
 
 int mlx5_devlink_eswitch_ipsec_mode_set(struct devlink *devlink,
-					enum devlink_eswitch_ipsec_mode ipsec,
-					struct netlink_ext_ack *extack)
+					enum devlink_eswitch_ipsec_mode ipsec
+#ifdef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+					, struct netlink_ext_ack *extack
+#endif
+)
 {
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	struct netlink_ext_ack *extack;
+#endif
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	struct mlx5_eswitch *esw = dev->priv.eswitch;
 	int err = 0;
 
+#ifndef HAVE_DEVLINK_ESWITCH_MODE_SET_EXTACK
+	extack = NULL;
+#else
 	memset(extack, 0, sizeof(*extack));
+#endif
 
 	esw = mlx5_devlink_eswitch_get(devlink);
 	if (IS_ERR(esw))
@@ -4517,12 +4573,20 @@ mlx5_devlink_eswitch_lag_port_select_mod
 	struct mlx5_core_dev *dev = devlink_priv(devlink);
 	u8 eswitch_mode = mlx5_eswitch_mode(dev);
 
-	if (mode == DEVLINK_ESWITCH_LAG_PORT_SELECT_MODE_HASH &&
-	    !MLX5_CAP_PORT_SELECTION(dev, port_select_flow_table)) {
+	if (mode == DEVLINK_ESWITCH_LAG_PORT_SELECT_MODE_HASH) {
+#ifndef HAVE_INFO_HASH_TYPE
 		mlx5_core_err(dev,
-			      "hash based LAG is not supported by current device");
+			      "hash based LAG is not supported by this kernel");
 		return -EOPNOTSUPP;
 	}
+#else
+		if (!MLX5_CAP_PORT_SELECTION(dev, port_select_flow_table)) {
+			mlx5_core_err(dev,
+				      "hash based LAG is not supported by current device");
+			return -EOPNOTSUPP;
+		}
+	}
+#endif
 
 	if (eswitch_mode == MLX5_ESWITCH_OFFLOADS) {
 		mlx5_core_err(dev,
