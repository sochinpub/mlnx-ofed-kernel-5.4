From: Valentine Fatiev <valentinef@mellanox.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/eswitch.c

Change-Id: I93fc4da02cf0f65bb66f9bcacde71ef397e1905a
---
 drivers/net/ethernet/mellanox/mlx5/core/eswitch.c | 48 +++++++++++++++++++++--
 1 file changed, 44 insertions(+), 4 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eswitch.c
@@ -64,6 +64,7 @@ struct vport_addr {
 	bool mc_promisc;
 };
 
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 struct mlx5_esw_vhca_mapping {
 	struct rhash_head node;
 	u16 vhca_id;
@@ -76,6 +77,7 @@ static const struct rhashtable_params vh
 	.key_len = sizeof(((struct  mlx5_esw_vhca_mapping *)0)->vhca_id),
 	.automatic_shrinking = true,
 };
+#endif
 
 DEFINE_IDA(mlx5e_vport_match_ida);
 DEFINE_MUTEX(mlx5e_vport_match_ida_mutex);
@@ -878,6 +880,7 @@ static bool element_type_supported(struc
 }
 
 /* Vport QoS management */
+#if IS_ENABLED(CONFIG_MLXDEVM)
 static int mlx5_devm_rate_group_register(struct mlx5_vgroup *group, const char *name)
 {
 	int err;
@@ -899,6 +902,7 @@ static void mlx5_devm_rate_group_unregis
 				      &group->devm);
 	kfree(group->devm.name);
 }
+#endif
 
 struct mlx5_vgroup *esw_create_vgroup(struct mlx5_eswitch *esw,
 				      u32 group_id, const char *name)
@@ -934,9 +938,13 @@ struct mlx5_vgroup *esw_create_vgroup(st
 	group->tsar_ix = tsar_ix;
 	group->dev = dev;
 
+#if IS_ENABLED(CONFIG_MLXDEVM)
 	if (name)
 		err = mlx5_devm_rate_group_register(group, name);
 	else
+#else
+	if (!name)
+#endif
 		err = mlx5_create_vf_group_sysfs(dev, group->group_id, &group->kobj);
 
 	if (err)
@@ -966,9 +974,13 @@ void esw_destroy_vgroup(struct mlx5_eswi
 
 	list_del(&group->list);
 
+#if IS_ENABLED(CONFIG_MLXDEVM)
 	if (group->devm.name)
 		mlx5_devm_rate_group_unregister(group);
 	else
+#else
+	if (!group->devm.name)
+#endif
 		mlx5_destroy_vf_group_sysfs(esw->dev, &group->kobj);
 
 	err = mlx5_destroy_scheduling_element_cmd(esw->dev,
@@ -1274,6 +1286,7 @@ static void esw_vport_cleanup_acl(struct
 		esw_vport_destroy_offloads_acl_tables(esw, vport);
 }
 
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 static int mlx5_esw_vport_vhca_id_mapping_get(struct mlx5_eswitch *esw, struct mlx5_vport *vport,
 					      u16 *vhca_id)
 {
@@ -1302,6 +1315,7 @@ out_free:
 	kfree(query_ctx);
 	return err;
 }
+#endif
 
 static int esw_vport_setup(struct mlx5_eswitch *esw, struct mlx5_vport *vport)
 {
@@ -1371,11 +1385,12 @@ static void esw_vport_cleanup(struct mlx
 int mlx5_eswitch_enable_vport(struct mlx5_eswitch *esw, u16 vport_num,
 			    enum mlx5_eswitch_vport_event enabled_events)
 {
-	struct mlx5_esw_vhca_mapping *m;
 	struct mlx5_vport *vport;
-	u16 vhca_id;
 	int ret = 0;
-
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
+	struct mlx5_esw_vhca_mapping *m;
+	u16 vhca_id;
+#endif
 	vport = mlx5_eswitch_get_vport(esw, vport_num);
 
 	mutex_lock(&esw->state_lock);
@@ -1404,6 +1419,7 @@ int mlx5_eswitch_enable_vport(struct mlx
 	    (!vport_num && mlx5_core_is_ecpf(esw->dev)))
 		vport->info.trusted = true;
 
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 	ret = mlx5_esw_vport_vhca_id_mapping_get(esw, vport, &vhca_id);
 	if (ret) {
 		esw_debug(esw->dev, "Failed to get VHCA_ID mapping to VPORT %d\n", vport_num);
@@ -1423,6 +1439,7 @@ int mlx5_eswitch_enable_vport(struct mlx
 		if (ret)
 			goto err_insert;
 	}
+#endif
 
 	/* External controller host PF has factory programmed MAC.
 	 * Read it from the device.
@@ -1435,6 +1452,7 @@ int mlx5_eswitch_enable_vport(struct mlx
 	esw->enabled_vports++;
 	esw_debug(esw->dev, "Enabled VPORT(%d)\n", vport_num);
 
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 	goto done;
 
 err_insert:
@@ -1443,11 +1461,13 @@ err_out:
 	vport->enabled = false;
 	vport->enabled_events = 0;
 	esw_vport_cleanup(esw, vport);
+#endif
 done:
 	mutex_unlock(&esw->state_lock);
 	return ret;
 }
 
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 static void mlx5_eswitch_free_vhca_id_mapping(struct mlx5_eswitch *esw, u16 vport_num)
 {
 	struct mlx5_esw_vhca_mapping *m;
@@ -1472,6 +1492,7 @@ static void mlx5_eswitch_free_vhca_id_ma
 		kfree(m);
 	}
 }
+#endif
 
 void mlx5_eswitch_disable_vport(struct mlx5_eswitch *esw, u16 vport_num)
 {
@@ -1490,7 +1511,9 @@ void mlx5_eswitch_disable_vport(struct m
 	/* Disable events from this vport */
 	arm_vport_context_events_cmd(esw->dev, vport->vport, 0);
 
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 	mlx5_eswitch_free_vhca_id_mapping(esw, vport_num);
+#endif
 
 	/* We don't assume VFs will cleanup after themselves.
 	 * Calling vport change handler while vport is disabled will cleanup
@@ -1965,8 +1988,11 @@ int mlx5_eswitch_enable(struct mlx5_eswi
 void mlx5_eswitch_disable_locked(struct mlx5_eswitch *esw, bool clear_vf)
 {
 	int old_mode;
-
+#ifdef HAVE_LOCKUP_ASSERT_HELD_WRITE
 	lockdep_assert_held_write(&esw->mode_lock);
+#else
+	lockdep_assert_held(&esw->mode_lock);
+#endif
 
 	if (esw->mode == MLX5_ESWITCH_NONE)
 		return;
@@ -2311,7 +2337,9 @@ int mlx5_eswitch_init(struct mlx5_core_d
 	hash_init(esw->offloads.route_tbl);
 	ida_init(&esw->offloads.vport_metadata_ida);
 	spin_lock_init(&esw->offloads.int_vports_lock);
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 	rhashtable_init(&esw->vhca_map_ht, &vhca_map_params);
+#endif
 	mutex_init(&esw->state_lock);
 	mutex_init(&esw->mode_lock);
 
@@ -2392,7 +2420,9 @@ void mlx5_eswitch_cleanup(struct mlx5_es
 	destroy_workqueue(esw->work_queue);
 	mutex_destroy(&esw->mode_lock);
 	mutex_destroy(&esw->state_lock);
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 	rhashtable_destroy(&esw->vhca_map_ht);
+#endif
 	ida_destroy(&esw->offloads.vport_metadata_ida);
 	mlx5e_mod_hdr_tbl_destroy(&esw->offloads.mod_hdr);
 	mutex_destroy(&esw->offloads.encap_tbl_lock);
@@ -2458,6 +2488,7 @@ int mlx5_eswitch_set_vport_mac(struct ml
 	return err;
 }
 
+#if IS_ENABLED(CONFIG_MLX5_CLS_ACT)
 int mlx5_eswitch_get_vport_from_vhca_id(struct mlx5_eswitch *esw, u16 vhca_id,
 					u16 *vport)
 {
@@ -2470,6 +2501,7 @@ int mlx5_eswitch_get_vport_from_vhca_id(
 	*vport = m->vport;
 	return 0;
 }
+#endif
 
 static bool mlx5_esw_check_port_type(struct mlx5_eswitch *esw, u16 vport_num, xa_mark_t mark)
 {
@@ -2725,9 +2757,13 @@ int mlx5_eswitch_get_vport_config(struct
 	ivi->linkstate = evport->info.link_state;
 	ivi->vlan = evport->info.vlan;
 	ivi->qos = evport->info.qos;
+#ifdef HAVE_VF_VLAN_PROTO
 	ivi->vlan_proto = evport->info.vlan_proto;
+#endif
 	ivi->spoofchk = evport->info.spoofchk;
+#ifdef HAVE_VF_INFO_TRUST
 	ivi->trusted = evport->info.trusted;
+#endif
 	ivi->min_tx_rate = evport->qos.min_rate;
 	ivi->max_tx_rate = evport->qos.max_rate;
 	mutex_unlock(&esw->state_lock);
@@ -3171,7 +3207,9 @@ int mlx5_eswitch_get_vport_stats(struct
 	struct mlx5_vport *vport = mlx5_eswitch_get_vport(esw, vport_num);
 	int outlen = MLX5_ST_SZ_BYTES(query_vport_counter_out);
 	u32 in[MLX5_ST_SZ_DW(query_vport_counter_in)] = {};
+#ifdef HAVE_STRUCT_IFLA_VF_STATS_RX_TX_DROPPED
 	struct mlx5_vport_drop_stats stats = {};
+#endif
 	int err = 0;
 	u32 *out;
 
@@ -3231,11 +3269,13 @@ int mlx5_eswitch_get_vport_stats(struct
 	vf_stats->broadcast =
 		MLX5_GET_CTR(out, received_eth_broadcast.packets);
 
+#ifdef HAVE_STRUCT_IFLA_VF_STATS_RX_TX_DROPPED
 	err = mlx5_esw_query_vport_drop_stats(esw->dev, vport, &stats);
 	if (err)
 		goto free_out;
 	vf_stats->rx_dropped = stats.rx_dropped;
 	vf_stats->tx_dropped = stats.tx_dropped;
+#endif
 
 free_out:
 	kvfree(out);
