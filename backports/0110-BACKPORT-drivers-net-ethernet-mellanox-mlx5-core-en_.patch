From: Mikhael Goikhman <migo@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c

Change-Id: I17ec3c99c182f50407955add9737beb48ce23d89
---
 .../net/ethernet/mellanox/mlx5/core/en_txrx.c | 55 ++++++++++++++++++-
 1 file changed, 54 insertions(+), 1 deletion(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_txrx.c
@@ -34,7 +34,9 @@
 #include "en.h"
 #include "en/txrx.h"
 #include "en/xdp.h"
+#ifdef HAVE_NDO_XSK_WAKEUP
 #include "en/xsk/rx.h"
+#endif
 #include "en/xsk/tx.h"
 #include "en/txrx.h"
 
@@ -88,9 +90,10 @@ void mlx5e_trigger_irq(struct mlx5e_icos
 	nopwqe = mlx5e_post_nop(wq, sq->sqn, &sq->pc);
 	mlx5e_notify_hw(wq, sq->pc, sq->uar_map, &nopwqe->ctrl);
 }
-
+#ifdef HAVE_XSK_SUPPORT
 static bool mlx5e_napi_xsk_post(struct mlx5e_xdpsq *xsksq, struct mlx5e_rq *xskrq)
 {
+#ifdef HAVE_NDO_XSK_WAKEUP
 	bool busy_xsk = false, xsk_rx_alloc_err;
 
 	/* Handle the race between the application querying need_wakeup and the
@@ -112,29 +115,48 @@ static bool mlx5e_napi_xsk_post(struct m
 					   xskrq);
 	busy_xsk |= mlx5e_xsk_update_rx_wakeup(xskrq, xsk_rx_alloc_err);
 
+#else
+	bool busy_xsk = false;
+
+	busy_xsk |= mlx5e_xsk_tx(xsksq, MLX5E_TX_XSK_POLL_BUDGET);
+	busy_xsk |= xskrq->post_wqes(xskrq);
+#endif
+
 	return busy_xsk;
 }
+#endif
 
 int mlx5e_napi_poll(struct napi_struct *napi, int budget)
 {
 	struct mlx5e_channel *c = container_of(napi, struct mlx5e_channel,
 					       napi);
 	struct mlx5e_ch_stats *ch_stats = c->stats;
+#ifdef HAVE_XSK_SUPPORT
 	struct mlx5e_xdpsq *xsksq = &c->xsksq;
 	struct mlx5e_rq *xskrq = &c->xskrq;
+#endif
 	struct mlx5e_rq *rq = &c->rq;
+#ifdef HAVE_XSK_SUPPORT
 	bool aff_change = false;
 	bool busy_xsk = false;
+#endif
 	bool busy = false;
 	int work_done = 0;
+#ifdef HAVE_XSK_SUPPORT
 	bool xsk_open;
+#endif
 	int i;
 
 	rcu_read_lock();
 
+#ifdef HAVE_XSK_SUPPORT
 	xsk_open = test_bit(MLX5E_CHANNEL_STATE_XSK, c->state);
+#endif
 
 	ch_stats->poll++;
+#ifndef HAVE_NAPI_STATE_MISSED
+	clear_bit(MLX5E_CHANNEL_NAPI_SCHED, &c->flags);
+#endif
 
 	for (i = 0; i < c->num_tc; i++)
 		busy |= mlx5e_poll_tx_cq(&c->sq[i].cq, budget);
@@ -144,14 +166,20 @@ int mlx5e_napi_poll(struct napi_struct *
 		busy |= mlx5e_poll_tx_cq(&c->special_sq[i].cq, budget);
 #endif
 
+#ifdef HAVE_XDP_REDIRECT
 	busy |= mlx5e_poll_xdpsq_cq(&c->xdpsq.cq);
+#endif
 
+#ifdef HAVE_XDP_BUFF
 	if (c->xdp)
 		busy |= mlx5e_poll_xdpsq_cq(&c->rq_xdpsq.cq);
+#endif
 
 	if (likely(budget)) { /* budget=0 means: don't poll rx rings */
+#ifdef HAVE_XSK_SUPPORT
 		if (xsk_open)
 			work_done = mlx5e_poll_rx_cq(&xskrq->cq, budget);
+#endif
 
 		if (likely(budget - work_done))
 			work_done += mlx5e_poll_rx_cq(&rq->cq, budget - work_done);
@@ -160,22 +188,26 @@ int mlx5e_napi_poll(struct napi_struct *
 	}
 
 	mlx5e_poll_ico_cq(&c->icosq.cq);
+#if defined HAVE_XSK_SUPPORT || defined HAVE_KTLS_RX_SUPPORT
 	if (mlx5e_poll_ico_cq(&c->async_icosq.cq))
 		/* Don't clear the flag if nothing was polled to prevent
 		 * queueing more WQEs and overflowing the async ICOSQ.
 		 */
 		clear_bit(MLX5E_SQ_STATE_PENDING_XSK_TX, &c->async_icosq.state);
+#endif
 
 	busy |= INDIRECT_CALL_2(rq->post_wqes,
 				mlx5e_post_rx_mpwqes,
 				mlx5e_post_rx_wqes,
 				rq);
+#ifdef HAVE_XSK_SUPPORT
 	if (xsk_open) {
 		busy |= mlx5e_poll_xdpsq_cq(&xsksq->cq);
 		busy_xsk |= mlx5e_napi_xsk_post(xsksq, xskrq);
 	}
 
 	busy |= busy_xsk;
+#endif
 
 	if (busy) {
 		if (likely(mlx5e_channel_no_affinity_change(c))) {
@@ -183,13 +215,25 @@ int mlx5e_napi_poll(struct napi_struct *
 			goto out;
 		}
 		ch_stats->aff_change++;
+#ifdef HAVE_XSK_SUPPORT
 		aff_change = true;
+#endif
 		if (budget && work_done == budget)
 			work_done--;
 	}
 
+#ifdef HAVE_NAPI_STATE_MISSED
 	if (unlikely(!napi_complete_done(napi, work_done)))
 		goto out;
+#else
+ 	napi_complete_done(napi, work_done);
+ 
+	/* avoid losing completion event during/after polling cqs */
+	if (test_bit(MLX5E_CHANNEL_NAPI_SCHED, &c->flags)) {
+		napi_schedule(napi);
+		goto out;
+	}
+#endif
 
 	ch_stats->arm++;
 
@@ -205,9 +249,14 @@ int mlx5e_napi_poll(struct napi_struct *
 
 	mlx5e_rx_dim_cq_rearm(c->priv, rq);
 	mlx5e_cq_arm(&c->icosq.cq);
+#if defined HAVE_XSK_SUPPORT || defined HAVE_KTLS_RX_SUPPORT
 	mlx5e_cq_arm(&c->async_icosq.cq);
+#endif
+#ifdef HAVE_XDP_REDIRECT
 	mlx5e_cq_arm(&c->xdpsq.cq);
+#endif
 
+#ifdef HAVE_XSK_SUPPORT
 	if (xsk_open) {
 		mlx5e_rx_dim_cq_rearm(c->priv, xskrq);
 		mlx5e_cq_arm(&xsksq->cq);
@@ -217,6 +266,7 @@ int mlx5e_napi_poll(struct napi_struct *
 		mlx5e_trigger_irq(&c->icosq);
 		ch_stats->force_irq++;
 	}
+#endif
 
 out:
 	rcu_read_unlock();
@@ -228,6 +278,9 @@ void mlx5e_completion_event(struct mlx5_
 {
 	struct mlx5e_cq *cq = container_of(mcq, struct mlx5e_cq, mcq);
 
+#ifndef HAVE_NAPI_STATE_MISSED
+	set_bit(MLX5E_CHANNEL_NAPI_SCHED, cq->ch_flags);
+#endif
 	napi_schedule(cq->napi);
 	cq->event_ctr++;
 	cq->ch_stats->events++;
