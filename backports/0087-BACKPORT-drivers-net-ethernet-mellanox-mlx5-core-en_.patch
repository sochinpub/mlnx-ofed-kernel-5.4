From: Mikhael Goikhman <migo@nvidia.com>
Subject: [PATCH] BACKPORT:
 drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_rxtx.c

Change-Id: Id55611d303c248018d2c88d76e7ea719247f67fb
---
 .../mellanox/mlx5/core/en_accel/ipsec_rxtx.c  | 59 ++++++++++++++++++-
 1 file changed, 58 insertions(+), 1 deletion(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_rxtx.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en_accel/ipsec_rxtx.c
@@ -233,6 +233,26 @@ static void mlx5e_ipsec_set_metadata(str
 		   ntohs(mdata->content.tx.seq));
 }
 
+/* Copy from upstream net/ipv4/esp4.c */
+#ifndef HAVE_ESP_OUTPUT_FILL_TRAILER
+	static
+void esp_output_fill_trailer(u8 *tail, int tfclen, int plen, __u8 proto)
+{ 
+	/* Fill padding... */
+	if (tfclen) {
+		memset(tail, 0, tfclen);
+		tail += tfclen;
+	}
+	do {
+		int i;
+		for (i = 0; i < plen - 2; i++)
+			tail[i] = i + 1;
+	} while (0);
+	tail[plen - 2] = plen - 2;
+	tail[plen - 1] = proto;
+}
+#endif
+
 void mlx5e_ipsec_handle_tx_wqe(struct mlx5e_tx_wqe *wqe,
 			       struct mlx5e_accel_tx_ipsec_state *ipsec_st,
 			       struct mlx5_wqe_inline_seg *inlseg)
@@ -318,12 +338,18 @@ bool mlx5e_ipsec_handle_tx_skb(struct ne
 	struct mlx5e_priv *priv = netdev_priv(netdev);
 	struct xfrm_offload *xo = xfrm_offload(skb);
 	struct mlx5e_ipsec_sa_entry *sa_entry;
-	struct mlx5e_ipsec_metadata *mdata;
+	struct mlx5e_ipsec_metadata *mdata = NULL;
 	struct xfrm_state *x;
+#ifdef SECPATH_SET_RETURN_POINTER
 	struct sec_path *sp;
+#endif
 
+#ifdef SECPATH_SET_RETURN_POINTER
 	sp = skb_sec_path(skb);
 	if (unlikely(sp->len != 1)) {
+#else
+	if (unlikely(skb->sp->len != 1)) {
+#endif
 		atomic64_inc(&priv->ipsec->sw_stats.ipsec_tx_drop_bundle);
 		goto drop;
 	}
@@ -376,11 +402,18 @@ mlx5e_ipsec_build_sp(struct net_device *
 	struct mlx5e_priv *priv = netdev_priv(netdev);
 	struct xfrm_offload *xo;
 	struct xfrm_state *xs;
+#ifdef SECPATH_SET_RETURN_POINTER
 	struct sec_path *sp;
+#endif
 	u32 sa_handle;
 
+#ifdef SECPATH_SET_RETURN_POINTER
 	sp = secpath_set(skb);
 	if (unlikely(!sp)) {
+#else
+	skb->sp = secpath_dup(skb->sp);
+	if (unlikely(!skb->sp)) {
+#endif
 		atomic64_inc(&priv->ipsec->sw_stats.ipsec_rx_drop_sp_alloc);
 		return NULL;
 	}
@@ -392,9 +425,14 @@ mlx5e_ipsec_build_sp(struct net_device *
 		return NULL;
 	}
 
+#ifdef SECPATH_SET_RETURN_POINTER
 	sp = skb_sec_path(skb);
 	sp->xvec[sp->len++] = xs;
 	sp->olen++;
+#else
+	skb->sp->xvec[skb->sp->len++] = xs;
+	skb->sp->olen++;
+#endif
 
 	xo = xfrm_offload(skb);
 	xo->flags = CRYPTO_DONE;
@@ -456,13 +494,20 @@ void mlx5e_ipsec_offload_handle_rx_skb(s
 	struct mlx5e_priv *priv;
 	struct xfrm_offload *xo;
 	struct xfrm_state *xs;
+#ifdef SECPATH_SET_RETURN_POINTER
 	struct sec_path *sp;
+#endif
 	u32  sa_handle;
 
 	sa_handle = MLX5_IPSEC_METADATA_HANDLE(ipsec_meta_data);
 	priv = netdev_priv(netdev);
+#ifdef SECPATH_SET_RETURN_POINTER
 	sp = secpath_set(skb);
 	if (unlikely(!sp)) {
+#else
+	skb->sp = secpath_dup(skb->sp);
+	if (unlikely(!skb->sp)) {
+#endif
 		atomic64_inc(&priv->ipsec->sw_stats.ipsec_rx_drop_sp_alloc);
 		return;
 	}
@@ -473,9 +518,14 @@ void mlx5e_ipsec_offload_handle_rx_skb(s
 		return;
 	}
 
+#ifdef SECPATH_SET_RETURN_POINTER
 	sp = skb_sec_path(skb);
 	sp->xvec[sp->len++] = xs;
 	sp->olen++;
+#else
+	skb->sp->xvec[skb->sp->len++] = xs;
+	skb->sp->olen++;
+#endif
 
 	xo = xfrm_offload(skb);
 	xo->flags = CRYPTO_DONE;
@@ -500,11 +550,18 @@ void mlx5e_ipsec_offload_handle_rx_skb(s
 bool mlx5e_ipsec_feature_check(struct sk_buff *skb, struct net_device *netdev,
 			       netdev_features_t features)
 {
+#ifdef SECPATH_SET_RETURN_POINTER
 	struct sec_path *sp = skb_sec_path(skb);
+#endif
 	struct xfrm_state *x;
 
+#ifdef SECPATH_SET_RETURN_POINTER
 	if (sp && sp->len) {
 		x = sp->xvec[0];
+#else
+	if (skb->sp && skb->sp->len) {
+		x = skb->sp->xvec[0];
+#endif
 		if (x && x->xso.offload_handle)
 			return true;
 	}
