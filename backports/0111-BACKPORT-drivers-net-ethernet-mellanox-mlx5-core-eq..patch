From: Shay Drory <shayd@nvidia.com>
Subject: [PATCH] BACKPORT: drivers/net/ethernet/mellanox/mlx5/core/eq.c

Change-Id: If6b763374504c19f5d28aeeba8e960092709a68a
---
 drivers/net/ethernet/mellanox/mlx5/core/eq.c | 38 ++++++++++++++++++--
 1 file changed, 36 insertions(+), 2 deletions(-)

--- a/drivers/net/ethernet/mellanox/mlx5/core/eq.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/eq.c
@@ -43,7 +43,9 @@ enum {
 	MLX5_EQ_POLLING_BUDGET	= 128,
 };
 
+#ifdef HAVE_STATIC_ASSERT
 static_assert(MLX5_EQ_POLLING_BUDGET <= MLX5_NUM_SPARE_EQE);
+#endif
 
 struct mlx5_eq_table {
 	struct list_head        comp_eqs_list;
@@ -123,7 +125,11 @@ static int mlx5_eq_comp_int(struct notif
 		/* Make sure we read EQ entry contents after we've
 		 * checked the ownership bit.
 		 */
+#ifdef dma_rmb
 		dma_rmb();
+#else
+		rmb();
+#endif
 		/* Assume (eqe->type) is always MLX5_EVENT_TYPE_COMP */
 		cqn = be32_to_cpu(eqe->data.comp.cqn) & 0xffffff;
 
@@ -200,7 +206,7 @@ static int mlx5_eq_async_int(struct noti
 	struct mlx5_eq_table *eqt;
 	struct mlx5_core_dev *dev;
 	struct mlx5_eqe *eqe;
-	unsigned long flags;
+	unsigned long flags = 0;
 	int num_eqes = 0;
 
 	dev = eq->dev;
@@ -217,7 +223,11 @@ static int mlx5_eq_async_int(struct noti
 		 * Make sure we read EQ entry contents after we've
 		 * checked the ownership bit.
 		 */
+#ifdef dma_rmb
 		dma_rmb();
+#else
+		rmb();
+#endif
 
 		atomic_notifier_call_chain(&eqt->nh[eqe->type], eqe->type, eqe);
 		atomic_notifier_call_chain(&eqt->nh[MLX5_EVENT_TYPE_NOTIFY_ANY], eqe->type, eqe);
@@ -321,7 +331,11 @@ create_map_eq(struct mlx5_core_dev *dev,
 
 	eq->vecidx = vecidx;
 	eq->eqn = MLX5_GET(create_eq_out, out, eq_number);
-	eq->irqn = pci_irq_vector(dev->pdev, vecidx);
+#ifdef HAVE_PCI_IRQ_API
+       eq->irqn = pci_irq_vector(dev->pdev, vecidx);
+#else
+	eq->irqn = mlx5_get_msix_vec(dev, vecidx);
+#endif
 	eq->dev = dev;
 	eq->doorbell = priv->uar->map + MLX5_EQ_DOORBEL_OFFSET;
 
@@ -772,7 +786,11 @@ mlx5_eq_create_generic(struct mlx5_core_
 	struct mlx5_eq *eq = kvzalloc(sizeof(*eq), GFP_KERNEL);
 	int err;
 
+#ifdef HAVE_CPUMASK_AVAILABLE
 	if (!cpumask_available(param->affinity))
+#else
+	if (!param->affinity)
+#endif
 		return ERR_PTR(-EINVAL);
 
 	if (!eq)
@@ -816,7 +834,11 @@ struct mlx5_eqe *mlx5_eq_get_eqe(struct
 	 * checked the ownership bit.
 	 */
 	if (eqe)
+#ifdef dma_rmb
 		dma_rmb();
+#else
+		rmb();
+#endif
 
 	return eqe;
 }
@@ -1038,8 +1060,13 @@ static int set_rmap(struct mlx5_core_dev
 	comp_base = mlx5_irq_table_comp_base_get(eq_table->irq_table);
 	vecidx = comp_base;
 	for (; vecidx < eq_table->num_comp_eqs + comp_base; vecidx++) {
+#ifdef HAVE_PCI_IRQ_API
 		err = irq_cpu_rmap_add(eq_table->rmap,
 				       pci_irq_vector(mdev->pdev, vecidx));
+#else
+		err = irq_cpu_rmap_add(eq_table->rmap,
+				       mdev->priv.msix_arr[vecidx].vector);
+#endif
 		if (err) {
 			mlx5_core_err(mdev, "irq_cpu_rmap_add failed. err %d",
 				      err);
@@ -1055,6 +1082,13 @@ err_out:
 	return err;
 }
 
+#ifndef HAVE_PCI_IRQ_API
+u32 mlx5_get_msix_vec(struct mlx5_core_dev *dev, int vecidx)
+{
+	return dev->priv.msix_arr[vecidx].vector;
+}
+#endif
+
 /* This function should only be called after mlx5_cmd_force_teardown_hca */
 void mlx5_core_eq_free_irqs(struct mlx5_core_dev *dev)
 {
